{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tandem++ Baseline Chatbot\n",
    "\n",
    "Train and fine-tune the chatbot on a curated dataset of German dialogue-specific data provided by team member 2, utilizing adaptors to work around limitations in fine-tuning the\n",
    "entire model while still generating appropriate and natural responses."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/german-gpt2\")\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"dbmdz/german-gpt2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation with GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallo! Wie geht's dir?\n",
      "Gut!\n",
      "- Gut.\n",
      "- Mir nicht so schlecht.\n",
      "Das ist ja noch schöner hier.\n",
      "Da ist er!\n",
      "Ich wollte den Kerl für die Party besuchen.\n",
      "Ich hab ihn erst nicht erkannt.\n",
      "Ja, du hast recht.\n",
      "Es gibt nichts Besseres.\n",
      "Wer ist das?\n",
      "Du bist neu hier.\n",
      "Deine Tochter, Shakia, wird auch auf dem Weg hiernach leben.\n",
      "Wo ist sie?\n",
      "Ich\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, Conversation\n",
    "\n",
    "pipe = pipeline('text-generation', model=\"dbmdz/german-gpt2\", tokenizer=\"dbmdz/german-gpt2\")\n",
    "text = pipe(\"Hallo! Wie geht's dir?\", max_length=100)[0][\"generated_text\"]\n",
    "print(text)\n",
    "\n",
    "# pipe = pipeline('conversational', model=\"dbmdz/german-gpt2\", tokenizer=\"dbmdz/german-gpt2\")\n",
    "# conversation = pipe([Conversation(\"Hallo! Wie geht's dir?\")])\n",
    "# print(conversation.generated_responses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuned GPT-2 Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
